{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.utils.data\n",
        "from scipy.io import loadmat\n",
        "from model.GMVAE import *\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "List of files ending with '.pth':\n",
            "checkpoint/model_3.pth\n",
            "> \u001b[0;32m/tmp/ipykernel_2473115/3387544945.py\u001b[0m(12)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     10 \u001b[0;31m\u001b[0;31m# Print the list of matching files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     11 \u001b[0;31m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"List of files ending with '.pth':\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 12 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatching_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     13 \u001b[0;31m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     14 \u001b[0;31m    \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "*** TypeError: 'Namespace' object is not subscriptable\n",
            "Namespace(file=None, dataset='cifar10', seed=0, cuda=1, gpuID=0, epochs=10, batch_size=64, batch_size_val=200, learning_rate=0.001, decay_epoch=-1, lr_decay=0.5, num_classes=10, gaussian_size=64, input_size=3072, train_proportion=1.0, init_temp=1.0, decay_temp=1, hard_gumbel=0, min_temp=0.5, decay_temp_rate=0.013862944, w_gauss=1, w_categ=1, w_rec=1, rec_type='mse', verbose=0, random_search_it=20, save_file='model_3', desc='cifar10')\n"
          ]
        }
      ],
      "source": [
        "# Directory containing the files\n",
        "folder_path = 'checkpoint'\n",
        "\n",
        "# Construct the pattern to match files ending with '.pth'\n",
        "file_pattern = os.path.join(folder_path, '*.pth')\n",
        "\n",
        "# Use glob to find files matching the pattern\n",
        "matching_files = glob.glob(file_pattern)\n",
        "\n",
        "# Print the list of matching files\n",
        "print(\"List of files ending with '.pth':\")\n",
        "for file in matching_files:\n",
        "    print(file)\n",
        "    checkpoint = torch.load(file, map_location=torch.device('cpu'))\n",
        "    args = params = checkpoint['config']\n",
        "    print(params.desc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = 'model_3'\n",
        "\n",
        "checkpoint = torch.load(f\"checkpoint/{model_name}.pth\", map_location=torch.device('cpu'))\n",
        "args = params = checkpoint['config']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Random Seed\n",
        "SEED = args.seed\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if args.cuda:\n",
        "  torch.cuda.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_dict = {\n",
        "    'mnist': datasets.MNIST,\n",
        "    'cifar10': datasets.CIFAR10,\n",
        "    'cifar100': datasets.CIFAR100\n",
        "}\n",
        "\n",
        "print(f\"Loading {args.dataset} dataset...\")\n",
        "# Download or load downloaded MNIST dataset\n",
        "train_dataset = dataset_dict[args.dataset](f'./data/{args.dataset}', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_dataset = dataset_dict[args.dataset](f'./data/{args.dataset}', train=False, transform=transforms.ToTensor())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8F6pjC7cNX7"
      },
      "outputs": [],
      "source": [
        "def partition_dataset(n, proportion=0.8):\n",
        "  train_num = int(n * proportion)\n",
        "  indices = np.random.permutation(n)\n",
        "  train_indices, val_indices = indices[:train_num], indices[train_num:]\n",
        "  return train_indices, val_indices\n",
        "\n",
        "if args.train_proportion == 1.0:\n",
        "  # we use all train dataset without partitioning\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
        "  test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.batch_size_val, shuffle=False)\n",
        "  val_loader = test_loader\n",
        "else:\n",
        "  # partition dataset according to train_proportion\n",
        "  train_indices, val_indices = partition_dataset(len(train_dataset), args.train_proportion)\n",
        "  # create data loaders for train, validation and test datasets\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, sampler=SubsetRandomSampler(train_indices))\n",
        "  val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size_val, sampler=SubsetRandomSampler(val_indices))\n",
        "  test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.batch_size_val, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt7sEfZWw_U7"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"params: {params}\")\n",
        "loss_history = checkpoint['loss_history']\n",
        "print(loss_history.keys())\n",
        "plt.plot(np.array(loss_history['train_history_nmi']), label='Train')\n",
        "plt.plot(np.array(loss_history['val_history_nmi']), label='Validation')\n",
        "\n",
        "# plt.plot(loss_history, label='KLD')\n",
        "plt.ylim([0, None])\n",
        "plt.title(f\"Training: NMI score\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "# plt.ylabel(\"KLD loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTncRSCuxFEL"
      },
      "outputs": [],
      "source": [
        "# Model Initialization\n",
        "params.cuda=False\n",
        "gmvae = GMVAE(params)\n",
        "gmvae.network.load_state_dict(checkpoint['model_state'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CimQtyl1foCj"
      },
      "source": [
        "## Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "rs2-BLGkfp8m",
        "outputId": "e908f506-815f-4332-9522-f34c73c9cc05"
      },
      "outputs": [],
      "source": [
        "accuracy, nmi = gmvae.test(test_loader)\n",
        "\n",
        "print(\"Testing phase...\")\n",
        "print(\"Accuracy: %.5lf,  NMI: %.5lf\" % (accuracy, nmi) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SbXR7FkhIcq"
      },
      "source": [
        "## Visualization of the feature latent space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTkEBA9JhQ2C"
      },
      "outputs": [],
      "source": [
        "# get feature representations\n",
        "test_features, test_labels = gmvae.latent_features(test_loader, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNmsz5rahZAY"
      },
      "outputs": [],
      "source": [
        "# import TSNE from scikit-learn library\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# reduce dimensionality to 2D, we consider a subset of data because TSNE\n",
        "# is a slow algorithm\n",
        "tsne_features = TSNE(n_components=2).fit_transform(test_features[:1000,])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "wyTtDdwyha-L",
        "outputId": "350e806a-6dd3-47f2-bd91-444aaf61b3dd"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.scatter(tsne_features[:, 0], tsne_features[:, 1], c=test_labels[:tsne_features.shape[0]], marker='o',\n",
        "            edgecolor='none', cmap=plt.cm.get_cmap('jet', 10), s = 10)\n",
        "plt.grid(False)\n",
        "plt.axis('off')\n",
        "plt.colorbar()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
